{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importing the numpy module which we will be using in this project\n",
    "import pandas as pd #importing the pandas module which will be used in this porject\n",
    "import string#importing the pandas module which will be used in this porject\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV#importing the test_train_split module which will be used in this porject\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #importing the classification report adn the confusion matrix module which will be used in this porject\n",
    "import nltk#importing the nltk module which will be used in this porject\n",
    "from nltk.corpus import stopwords#importing the nltk.corpus.stopwords module which will be used in this porject\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer#importing the extraction.text.CountVectorizer and TfidfTransformer module which will be used in this porject\n",
    "from sklearn.pipeline import Pipeline#importing the sklearn.pipeline.Pipeline module which will be used in this porject\n",
    "from sklearn.ensemble import RandomForestClassifier#importing the sklearn.ensemble.RandomForestClassifier module which will be used in this porject\n",
    "from sklearn.svm import SVC#importing the sklearn.svm.SVC module which will be used in this porject\n",
    "from sklearn.linear_model import LogisticRegression#importing the sklearn.linear_model.LogisticRegression module which will be used in this porject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ps75u7406\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love great upgrad origin i 've mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>veri nice set good qualiti we set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            category  rating label  \\\n",
       "0           0  Home_and_Kitchen_5     5.0    CG   \n",
       "1           1  Home_and_Kitchen_5     5.0    CG   \n",
       "2           2  Home_and_Kitchen_5     5.0    CG   \n",
       "3           3  Home_and_Kitchen_5     1.0    CG   \n",
       "4           4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                              text_  \n",
       "0  love well made sturdi comfort i love veri pretti  \n",
       "1    love great upgrad origin i 've mine coupl year  \n",
       "2      thi pillow save back i love look feel pillow  \n",
       "3             miss inform use great product price i  \n",
       "4       veri nice set good qualiti we set two month  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('dataset.csv') #reading our dataset which contains text and a label whether it is fake or real\n",
    "dataframe.head() #printing the first 5 columsn in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop('Unnamed: 0',axis=1,inplace=True)## dropping the unnecessary column 'UNAMED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love great upgrad origin i 've mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>veri nice set good qualiti we set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                              text_  \n",
       "0  love well made sturdi comfort i love veri pretti  \n",
       "1    love great upgrad origin i 've mine coupl year  \n",
       "2      thi pillow save back i love look feel pillow  \n",
       "3             miss inform use great product price i  \n",
       "4       veri nice set good qualiti we set two month  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head() #pritning the dataset again after dropping the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.dropna(inplace=True) #dropping alll the null rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['length'] = dataframe['text_'].apply(len) #storing the length of all the text into a separate column called 'length'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the largest review..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weak on current scienc after see twice i agre much posit five star review out respect read review i 'll repeat everyth i like present i found goofi over ear hairdo facial hair arrang daniel vitali describ `` wild food expert '' distract ugh ditto david wolf extrem goofi wild hairdo on hand jon gabriel describ `` author weight loss expert '' nice groom good present hi stori person transform fellow pound whew becom jock normal weight inspir christian northrup preserv rank one america 's cutest doctor a realli nice look woman present dr. mercola jason vale kri carr alejandro junger fine it disappoint jami oliv popular uk give babi cow growth fluid pas unscientif popular idea milk none present anyth zilch say work doctor t. colin campbel milk bodi bad it good see present take stand sugar they agre evil sugar refin carbohydr with respect dr. northrup `` it 's fat make fat 's sugar '' statement pas muster commun expert recogn evil sugar not mutual exclus recogn proven danger fat particularli fat dead anim extract fat all kind oliv oil not health food data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-china-study-the-most-comprehensive-study-of-nutrition-ever-conducted-and-the-startling-implications-for-diet-weight-loss-and-long-term-health/dp/1932100660/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the china studi the most comprehens studi nutrit ever conduct and startl implic diet weight loss and long-term health /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /forks-over-knives/dp/b0053zhzi2/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' fork over knive /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /prevent-and-reverse-heart-disease-the-revolutionary-scientifically-proven-nutrition-based-cure/dp/1583333002/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' prevent revers heart diseas the revolutionari scientif proven nutrition-bas cure /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-plant-based-journey-a-step-by-step-guide-for-transitioning-to-a-healthy-lifestyle-and-achieving-your-ideal-weight/dp/1941631363/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the plant-bas journey a step-by-step guid transit healthi lifestyl achiev your ideal weight /a\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['label']=='OR'][['text_','length']].sort_values(by='length',ascending=False).head().iloc[0].text_ ##so here we are just collecting the words which are most common in the fake reviews so that we can identify these wrods to detect for future text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmyTxt(rv): #here we areA defining a function\n",
    "    np = [c for c in rv if c not in string.punctuation] #this function is checking if it is present in punctuation or not.\n",
    "    np = ''.join(np) #the character which are not in punctuation, we are storing them in a separate string\n",
    "    return [w for w in np.split() if w.lower() not in stopwords.words('english')] #here we are returning a list of words from the sentences we just made in above line and checking if it is not a stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataframe['text_'],dataframe['label'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "]) #here we are defining our Random Forest Classifier model in which we will pass the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip.fit(x_train,y_train) #here we are passing the testing and training data into Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestClassifier = pip.predict(x_test) #here we are predicting the accuracy of the Random Forest Classifier model\n",
    "randomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_csv = pd.concat([pd.DataFrame(x_test).reset_index(drop=True),pd.DataFrame(randomForestClassifier)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(pip, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "# import module \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "HEADERS = ({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\ AppleWebKit/537.36 (KHTML, like Gecko) \\ Chrome/90.0.4430.212 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'}) \n",
    "\n",
    "# user define function \n",
    "# Scrape the data \n",
    "def getdata(url): \n",
    "    r = requests.get(url, headers=HEADERS,verify=False) \n",
    "    return r.text \n",
    "\n",
    "\n",
    "def html_code(url): \n",
    "\n",
    "\t# pass the url \n",
    "\t# into getdata function \n",
    "    htmldata = getdata(url) \n",
    "    soup = BeautifulSoup(htmldata, 'html.parser') \n",
    "\n",
    "\t# display html code \n",
    "    return (soup) \n",
    "\n",
    "\n",
    "url = \"https://www.amazon.in/Columbia-Mens-wind-\\ resistant-Glove/dp/B0772WVHPS/?_encoding=UTF8&pd_rd\\ _w=d9RS9&pf_rd_p=3d2ae0df-d986-4d1d-8c95-aa25d2ade606&pf\\ _rd_r=7MP3ZDYBBV88PYJ7KEMJ&pd_rd_r=550bec4d-5268-41d5-\\ 87cb-8af40554a01e&pd_rd_wg=oy8v8&ref_=pd_gw_cr_cartx&th=1\" \n",
    "\n",
    "soup = html_code(url) \n",
    "\n",
    "\n",
    "def cus_rev(soup): \n",
    "\t# find the Html tag \n",
    "\t# with find() \n",
    "\t# and convert into string \n",
    "    data_str = \"\" \n",
    "    for item in soup.find_all(\"div\", class_= \"a-expander-content reviewText review-text-content a-expander-partial-collapse-content\"): \n",
    "        data_str = data_str + item.get_text() \n",
    "#     for item in soup.find_all(\"div\", class_=\"a-expander-content \\ reviewText review-text-content a-expander-partial-collapse-content\"): \n",
    "#         print(item)\n",
    "#         data_str = data_str + item.get_text() \n",
    "\n",
    "    result = data_str.split(\"\\n\") \n",
    "    return (result) \n",
    "\n",
    "rev_data = cus_rev(soup) \n",
    "rev_result = [] \n",
    "for i in rev_data: \n",
    "        if i is \"\": \n",
    "            pass\n",
    "        else: \n",
    "            rev_result.append(i) \n",
    "df = pd.DataFrame(rev_result)\n",
    "df.rename(column = {0:\"review\"})\n",
    "df.to_csv('amazon_review.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {0:\"review\"},inplace=True)\n",
    "df.to_csv('amazon_review.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Columbia quality is the best in sports brands\n",
       "1      I would not recommend this product for winters.\n",
       "2                                       Somewhat small\n",
       "3                                                 Good\n",
       "4    I normally wear size L and this size L fits ve...\n",
       "5    This pair of gloves is not for very cold tempe...\n",
       "6    I took the advice of all the reviews and order...\n",
       "7    I had a pair of Columbia gloves from a few yea...\n",
       "8                 these gloves are just what i wanted.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.read_csv('amazon_review.csv')\n",
    "validation['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Columbia quality is the best in sports brands</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would not recommend this product for winters.</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat small</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I normally wear size L and this size L fits ve...</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This pair of gloves is not for very cold tempe...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I took the advice of all the reviews and order...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I had a pair of Columbia gloves from a few yea...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>these gloves are just what i wanted.</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   0\n",
       "0      Columbia quality is the best in sports brands  OR\n",
       "1    I would not recommend this product for winters.  OR\n",
       "2                                     Somewhat small  OR\n",
       "3                                               Good  OR\n",
       "4  I normally wear size L and this size L fits ve...  CG\n",
       "5  This pair of gloves is not for very cold tempe...  OR\n",
       "6  I took the advice of all the reviews and order...  OR\n",
       "7  I had a pair of Columbia gloves from a few yea...  OR\n",
       "8               these gloves are just what i wanted.  OR"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result  = pipeline.predict(validation['review'])\n",
    "pd.concat([pd.DataFrame(validation['review']).reset_index(drop=True),pd.DataFrame(val_result)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e00f5a600eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy of the model: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandomForestClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#here we are predicting the accuracy of the Random Forest Classifier model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model: ',str(np.round(accuracy_score(y_test,randomForestClassifier)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',SVC())\n",
    "])#here we are defining our Support Vector Classifier model in which we will pass the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.fit(x_train,y_train)#here we are passing the testing and training data into Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supportVectorClassifier = pip.predict(x_test)#here we are predicting the accuracy of the Random Forest Classifier model\n",
    "supportVectorClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy of the model:',str(np.round(accuracy_score(y_test,supportVectorClassifier)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pip, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result  = pipeline.predict(validation['review'])\n",
    "pd.concat([pd.DataFrame(validation['review']).reset_index(drop=True),pd.DataFrame(val_result)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',LogisticRegression())\n",
    "])#here we are defining our Logistic Regression model in which we will pass the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.fit(x_train,y_train)#here we are passing the testing and training data into Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression = pip.predict(x_test)#here we are predicting the accuracy of the Random Forest Classifier model\n",
    "logisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy of the model:',str(np.round(accuracy_score(y_test,logisticRegression)*100,2)) + '%')#here we are predicting the accuracy of the Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
