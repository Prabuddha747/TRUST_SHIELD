{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.amazon.in/Columbia-Mens-wind-\\ resistant-Glove/dp/B0772WVHPS/?_encoding=UTF8&pd_rd\\ _w=d9RS9&pf_rd_p=3d2ae0df-d986-4d1d-8c95-aa25d2ade606&pf\\ _rd_r=7MP3ZDYBBV88PYJ7KEMJ&pd_rd_r=550bec4d-5268-41d5-\\ 87cb-8af40554a01e&pd_rd_wg=oy8v8&ref_=pd_gw_cr_cartx&th=1\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importing the numpy module which we will be using in this project\n",
    "import pandas as pd #importing the pandas module which will be used in this porject\n",
    "import joblib\n",
    "import string#importing the pandas module which will be used in this porject\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV#importing the test_train_split module which will be used in this porject\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #importing the classification report adn the confusion matrix module which will be used in this porject\n",
    "import nltk#importing the nltk module which will be used in this porject\n",
    "from nltk.corpus import stopwords#importing the nltk.corpus.stopwords module which will be used in this porject\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer#importing the extraction.text.CountVectorizer and TfidfTransformer module which will be used in this porject\n",
    "from sklearn.pipeline import Pipeline#importing the sklearn.pipeline.Pipeline module which will be used in this porject\n",
    "from sklearn.ensemble import RandomForestClassifier#importing the sklearn.ensemble.RandomForestClassifier module which will be used in this porject\n",
    "from sklearn.svm import SVC#importing the sklearn.svm.SVC module which will be used in this porject\n",
    "from sklearn.linear_model import LogisticRegression#importing the sklearn.linear_model.LogisticRegression module which will be used in this porject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ps75u7406\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmyTxt(rv): #here we areA defining a function\n",
    "    np = [c for c in rv if c not in string.punctuation] #this function is checking if it is present in punctuation or not.\n",
    "    np = ''.join(np) #the character which are not in punctuation, we are storing them in a separate string\n",
    "    return [w for w in np.split() if w.lower() not in stopwords.words('english')] #here we are returning a list of words from the sentences we just made in above line and checking if it is not a stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function convertmyTxt at 0x0000011A4AAD4730>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "# import module \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "HEADERS = ({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\ AppleWebKit/537.36 (KHTML, like Gecko) \\ Chrome/90.0.4430.212 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'}) \n",
    "\n",
    "# user define function \n",
    "# Scrape the data \n",
    "def getdata(url): \n",
    "    r = requests.get(url, headers=HEADERS,verify=False) \n",
    "    return r.text \n",
    "\n",
    "\n",
    "def html_code(url): \n",
    "\n",
    "\t# pass the url \n",
    "\t# into getdata function \n",
    "    htmldata = getdata(url) \n",
    "    soup = BeautifulSoup(htmldata, 'html.parser') \n",
    "\n",
    "\t# display html code \n",
    "    return (soup) \n",
    "\n",
    "\n",
    "url = URL\n",
    "soup = html_code(url) \n",
    "\n",
    "\n",
    "def cus_rev(soup): \n",
    "\t# find the Html tag \n",
    "\t# with find() \n",
    "\t# and convert into string \n",
    "    data_str = \"\" \n",
    "    for item in soup.find_all(\"div\", class_= \"a-expander-content reviewText review-text-content a-expander-partial-collapse-content\"): \n",
    "        data_str = data_str + item.get_text() \n",
    "#     for item in soup.find_all(\"div\", class_=\"a-expander-content \\ reviewText review-text-content a-expander-partial-collapse-content\"): \n",
    "#         print(item)\n",
    "#         data_str = data_str + item.get_text() \n",
    "\n",
    "    result = data_str.split(\"\\n\") \n",
    "    return (result) \n",
    "\n",
    "rev_data = cus_rev(soup) \n",
    "rev_result = [] \n",
    "for i in rev_data: \n",
    "        if i is \"\": \n",
    "            pass\n",
    "        else: \n",
    "            rev_result.append(i) \n",
    "df = pd.DataFrame(rev_result)\n",
    "df.rename(columns = {0:\"review\"},inplace=True)\n",
    "df.to_csv('amazon_review.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv('amazon_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result  = pipeline.predict(validation['review'])\n",
    "final_result = pd.concat([pd.DataFrame(validation['review']).reset_index(drop=True),pd.DataFrame(val_result)],axis = 1)\n",
    "final_result.to_csv(\"Categorize_amazon_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Columbia quality is the best in sports brands</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would not recommend this product for winters.</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat small</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I normally wear size L and this size L fits ve...</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This pair of gloves is not for very cold tempe...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I took the advice of all the reviews and order...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I had a pair of Columbia gloves from a few yea...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>these gloves are just what i wanted.</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   0\n",
       "0      Columbia quality is the best in sports brands  OR\n",
       "1    I would not recommend this product for winters.  OR\n",
       "2                                     Somewhat small  OR\n",
       "3                                               Good  OR\n",
       "4  I normally wear size L and this size L fits ve...  CG\n",
       "5  This pair of gloves is not for very cold tempe...  OR\n",
       "6  I took the advice of all the reviews and order...  OR\n",
       "7  I had a pair of Columbia gloves from a few yea...  OR\n",
       "8               these gloves are just what i wanted.  OR"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
